<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">6 things you can do with JBang but you can’t with Shell</title><link rel="alternate" href="http://www.mastertheboss.com/java/jbang-vs-jshell/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/java/jbang-vs-jshell/</id><updated>2022-02-28T13:33:54Z</updated><content type="html">Using Java as scripting language has become a popular option in the last few years thanks to the JShell tool. In this article we will learn how the JBang scripting tool can take your Java scripting power at another level. Automatic fetching of dependencies The most impressing feature of JBang is dependency management. You can ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Simplify container development with Red Hat CodeReady Workspaces</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/02/28/simplify-container-development-red-hat-codeready-workspaces" /><author><name>Kasturi Mohan</name></author><id>65c8f602-20e2-4efb-abce-76bb37e69f75</id><updated>2022-02-28T07:00:00Z</updated><published>2022-02-28T07:00:00Z</published><summary type="html">&lt;p&gt;Developers who are frustrated with waiting for development environments to be set up, waiting for special laptops to be assigned, switching context between projects and branches, or other bottlenecks to launching a project should check out &lt;a href="https://access.redhat.com/products/red-hat-codeready-workspaces"&gt;Red Hat CodeReady Workspaces&lt;/a&gt;. This service makes it simple to use &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt; without having to be a &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; expert.&lt;/p&gt; &lt;p&gt;Does this sound like life in a magical fairyland? This article explains what CodeReady Workspaces offers and suggests five use cases where you can enjoy its benefits.&lt;/p&gt; &lt;h2&gt;Red Hat CodeReady Workspaces&lt;/h2&gt; &lt;p&gt;Red Hat CodeReady Workspaces is built on the open source &lt;a href="https://www.eclipse.org/che/"&gt;Eclipse Che&lt;/a&gt; project. The default integrated development environment (IDE) of the Che development environment is &lt;a href="https://theia-ide.org"&gt;Eclipse Theia&lt;/a&gt;. You need only a web browser to get access to a feature-rich IDE and benefit from shared extensions with the popular &lt;a href="https://code.visualstudio.com"&gt;Visual Studio Code&lt;/a&gt; (&lt;a href="https://developers.redhat.com/products/vscode-extensions/overview"&gt;VS Code&lt;/a&gt;) IDE, to which Theia has a similar look and feel. The experience is as fast and familiar as using an IDE on your laptop.&lt;/p&gt; &lt;p&gt;Red Hat CodeReady Workspaces is not new; it has been around for five years and has been built together with the community. After all, who else knows the pain of a developer better than a developer?&lt;/p&gt; &lt;p&gt;When you create a workspace in CodeReady Workspaces, the code editor is open, your project is loaded, and all the tools and language support you need are all right there. You can define many workspaces and easily switch between them. Start and stop workspaces with a click. When you are done, close the browser. You can restart the workspace later from the same computer or a different one. Indeed, all you need is a browser.&lt;/p&gt; &lt;h2&gt;Use cases and benefits&lt;/h2&gt; &lt;p&gt;Here are five use cases where CodeReady Workspaces can make a significant difference.&lt;/p&gt; &lt;h3&gt;1: IT is moving to Kubernetes for production, but my developers aren't Kubernetes experts and its learning curve is steep&lt;/h3&gt; &lt;p&gt;With Red Hat CodeReady Workspaces, all a developer needs is internet access and a browser. You can start coding with your application and development environment automatically containerized and running on OpenShift. We have made Kubernetes and containers invisible.&lt;/p&gt; &lt;h3&gt;2: Working locally on a laptop makes it hard to share and secure everything a developer needs&lt;/h3&gt; &lt;p&gt;From the beginning, the upstream Eclipse Che project (on which Red Hat CodeReady Workspaces is built) set out to use a different paradigm. Che places everything the developer needs in a set of containers so each developer can have their own development pod that feels like their laptop. At the same time, the environment is easy to share and more secure.&lt;/p&gt; &lt;h3&gt;3: My development consultants aren't as efficient as I need them to be&lt;/h3&gt; &lt;p&gt;Red Hat CodeReady Workspaces allows near-instant provisioning of a new developer, reproducing the production environment with familiar tools. This also makes obsolete the complaint "It worked on my laptop" when something goes wrong during testing or production.&lt;/p&gt; &lt;h3&gt;4: Virtual desktop infrastructure (VDI) solutions are slow and painful for developers, making them less agile and effective&lt;/h3&gt; &lt;p&gt;With Red Hat CodeReady Workspaces, you can use any machine (even a mobile device) and immediately begin contributing to projects, using a pre-secured environment for development.&lt;/p&gt; &lt;h3&gt;5: Failed CI/CD builds are costing a lot of money and time&lt;/h3&gt; &lt;p&gt;Red Hat CodeReady Workspaces can link you directly to the branch and commit for a failed CI/CD (continuous integration/continuous delivery) build, saving diagnostic time. You can create a workspace link for each release, so rebuilding an old environment is as fast as clicking a link. There is no setup required. All you need, once again, is a device with a browser and internet access.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;These are some use cases and ways Red Hat CodeReady Workspaces helps you be successful and agile. &lt;/p&gt; &lt;p&gt;With every release, we strive to make developers' and administrators' lives easier. Our release cycles are approximately every six weeks. The latest release was CodeReady Workspaces 2.15, released on Feb 15, 2022. Check out what's &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/2.15/html/release_notes_and_known_issues/new-features"&gt;new and noteworthy in 2.15.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;CodeReady Workspaces comes free with &lt;a href="https://developers.redhat.com/products/openshift"&gt;Red Hat OpenShift&lt;/a&gt;. You can try it out at no cost as part of &lt;a href="https://developers.redhat.com/developer-sandbox/get-started"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;So what are you waiting for? Developers: On your mark, get set, code!&lt;/p&gt; &lt;h3&gt;Resources to start your quick development journey&lt;/h3&gt; &lt;p&gt;To see a demo or to start developing on CodeReady Workspaces, reach out to me at &lt;a href="mailto:kmohan@redhat.com"&gt;kmohan@redhat.com&lt;/a&gt;. You can also explore the following resources:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview"&gt;CodeReady Workspaces&lt;/a&gt;: Visit our product page to learn more.&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/2.14/html-single/installation_guide/index"&gt;Installation guide&lt;/a&gt;: Read the documentation to get started.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/eclipse/che/wiki/Roadmap#eclipse-che-roadmap"&gt;Eclipse Che roadmap&lt;/a&gt;: Dive into our past, present, and future.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/eclipse/che/wiki/How-To-Contribute"&gt;How to contribute&lt;/a&gt;: Work with us to make CodeReady Workspaces a product that's by you for you.&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/02/28/simplify-container-development-red-hat-codeready-workspaces" title="Simplify container development with Red Hat CodeReady Workspaces"&gt;Simplify container development with Red Hat CodeReady Workspaces&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Kasturi Mohan</dc:creator><dc:date>2022-02-28T07:00:00Z</dc:date></entry><entry><title type="html">How to configure Logging with Quarkus</title><link rel="alternate" href="http://www.mastertheboss.com/soa-cloud/quarkus/how-to-configure-logging-with-quarkus/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/soa-cloud/quarkus/how-to-configure-logging-with-quarkus/</id><updated>2022-02-25T11:23:11Z</updated><content type="html">Quarkus uses the JBoss Log Manager project as facade for application logging. Therefore, the main configuration options should be familiar to JBoss/WildFly users. Let’s see how to configure most common options. Quarkus logging in a nutshell To use Logging with Quarkus you don’t need to include any extra dependency in your project. As a matter ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Enforce code consistency with clang-format</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/02/25/enforce-code-consistency-clang-format" /><author><name>Serge Guelton</name></author><id>54248eb6-d1bd-4c0c-a223-e675837870a7</id><updated>2022-02-25T07:00:00Z</updated><published>2022-02-25T07:00:00Z</published><summary type="html">&lt;p&gt;Imposing a common coding style can improve the readability and maintainability of your code in shared projects. Code consistency is particularly important in &lt;a href="https://developers.redhat.com/topics/open-source"&gt;open source&lt;/a&gt; projects, where contributors often revise code written by others. Code styling can also be especially challenging in open source projects because different contributors have their own style preferences. This article introduces &lt;a href="https://clang.llvm.org/docs/ClangFormat.html"&gt;clang-format&lt;/a&gt;, an uncomplicated tool that you can use to set a common code style for your team projects written &lt;a href="https://developers.redhat.com/topics/c"&gt;C, C++&lt;/a&gt;, and Objective C.&lt;/p&gt; &lt;p&gt;As an example for our discussion, I'll use &lt;a href="https://github.com/xtensor-stack/xsimd"&gt;xsimd&lt;/a&gt;, a project I contribute to, which enables the manipulation of batches of numbers with the same arithmetic operators used for single values. I will show you how to choose a code style, convert an existing codebase to that new style, and enforce the code style on future commits.&lt;/p&gt; &lt;p&gt;Note that &lt;code&gt;clang-format&lt;/code&gt; is part of the &lt;a href="https://llvm.org"&gt;LLVM project&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Introducing clang-format&lt;/h2&gt; &lt;p&gt;&lt;code&gt;clang-format&lt;/code&gt; is a tool that auto-formats &lt;a href="https://developers.redhat.com/topics/c"&gt;C, C++&lt;/a&gt;, and Objective C, much as the venerable &lt;a href="https://www.gnu.org/software/indent/"&gt;indent&lt;/a&gt; tool does for C. You can run the tool like this:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; clang-format -i my/source/file.cpp &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Executing this command will format &lt;code&gt;my/source/file.cpp&lt;/code&gt; according to the default style. Omitting &lt;code&gt;-i&lt;/code&gt; dumps the indented content on the standard output instead of modifying the input in place.&lt;/p&gt; &lt;p&gt;The default style is the one used by the LLVM project itself, but you can provide your own style guide in the form of a &lt;code&gt;.clang-format&lt;/code&gt; file. &lt;code&gt;clang-format&lt;/code&gt; automatically looks for a &lt;code&gt;.clang-format&lt;/code&gt; file in the current folder; if it cannot find one, it goes up one level in the directory tree and looks there, repeating the process until it finds one or reaches the root directory (&lt;code&gt;/&lt;/code&gt;). Only then does it fall back to the default LLVM style.&lt;/p&gt; &lt;p&gt;Among other settings, &lt;code&gt;clang-format&lt;/code&gt; can normalize the spacing before and after commas, positioning of brackets, alignments of arguments, and the maximum column width.&lt;/p&gt; &lt;h2&gt;Explore your code styling options&lt;/h2&gt; &lt;p&gt;Instead of walking through all the different formatting directives that might go into a &lt;code&gt;.clang-format&lt;/code&gt; file, you can use the &lt;a href="https://zed0.co.uk/clang-format-configurator/"&gt;clang-format configurator&lt;/a&gt;. This web application makes it possible to interactively explore different styling options and watch their impact on a codebase. Once you've found the style you like, the configurator will dump the associated configuration for you. In the case of the &lt;code&gt;xsimd&lt;/code&gt; project, we ended up with the following:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; --- BasedOnStyle: WebKit AlignAfterOpenBracket: Align AlignConsecutiveDeclarations: 'false' BreakBeforeBraces: Allman NamespaceIndentation: All ... &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Note that using the right &lt;code&gt;BasedOnStyle&lt;/code&gt; entry helps keep the configuration to a minimum. The configurator gives you a list of styles you can choose from for this option. For instance, the option &lt;code&gt;PointerAlignment: Left|Right|Middle&lt;/code&gt; lets you enforce consistent positioning for &lt;code&gt;*&lt;/code&gt; in pointer types, such as choosing between &lt;code&gt;int* foo&lt;/code&gt;, &lt;code&gt;int *foo&lt;/code&gt;, and &lt;code&gt;int * foo&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Normalize an existing project&lt;/h2&gt; &lt;p&gt;Once you've chosen your code style, you need to format your codebase to comply with it. Picking a style and sticking to it from day one is probably the easiest route, but we didn't have that foresight with &lt;code&gt;xsimd&lt;/code&gt;. Instead, we ran a very old-school &lt;code&gt;find -name '*.[ch]pp' -exec clang-format -i {} \;&lt;/code&gt; to format the whole codebase, and we pushed the change in a single commit. Our approach was debatable, as it does not interact well with later &lt;code&gt;git blame&lt;/code&gt; calls. You can use the &lt;a href="https://git-scm.com/docs/git-blame#Documentation/git-blame.txt---ignore-revs-fileltfilegt"&gt;--ignore-revs-file&lt;/a&gt; option to ignore bulk reformatting commits in &lt;code&gt;git blame&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Alternatively, it is possible to only apply styling to new commits, which avoids messing with your project's history. If you go that route, the LLVM project provides a utility tool named &lt;code&gt;clang-format-diff&lt;/code&gt; to format patches, though that's beyond the scope of this article.&lt;/p&gt; &lt;p&gt;Changing the style of a codebase shouldn’t affect the build. However, it is important to understand that &lt;code&gt;clang-format&lt;/code&gt; may reorder includes (though that is, of course, a configurable choice). Using &lt;code&gt;clang-format&lt;/code&gt; could reveal hidden dependencies between headers, and thus break the build. That said, it is probably a good idea to fix implicit header dependencies, anyway.&lt;/p&gt; &lt;h2&gt;Enforce the new coding rules&lt;/h2&gt; &lt;p&gt;Even if you establish coding rules for a project, new contributors may not be aware of them. Mentioning &lt;code&gt;clang-format&lt;/code&gt; and its usage in a &lt;code&gt;CONTRIBUTING.md&lt;/code&gt; file is a good idea. Here is what we wrote for &lt;code&gt;xsimd&lt;/code&gt;:&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;em&gt;We use &lt;a href="https://clang.llvm.org/docs/ClangFormat.html"&gt;clang-format&lt;/a&gt; to keep the coding style consistent. A &lt;code&gt;.clang-format&lt;/code&gt; file is shipped within the source. Feel free to use it!&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Education is nice, but automation also helps. Setting up a GitHub Action to check new pull requests with &lt;code&gt;clang-format&lt;/code&gt; helps inform contributors—that red &lt;a href="https://developers.redhat.com/topics/ci-cd"&gt;continuous integration&lt;/a&gt; icon definitely gets their attention! Here is the content of our &lt;code&gt;.github/workflows/clang-format-check.yml&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; name: clang-format on: [push, pull_request] jobs: formatting-check: name: Format check runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Run clang-format style check for C/C++ programs. uses: jidicula/clang-format-action@v4.2.0 with: clang-format-version: '13' &lt;/code&gt; &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This article briefly described how we deployed &lt;code&gt;clang-format&lt;/code&gt; on the existing codebase of an example project, &lt;code&gt;xsimd&lt;/code&gt;. I covered the process from choosing a code style to converting the codebase to enforcing the code style on future commits. Once you've set this all up, you can forget formatting nits and focus on coding.&lt;/p&gt; &lt;h3&gt;Acknowledgments&lt;/h3&gt; &lt;p&gt;I would like to thank Konrad Kleine and Tom Stellard for reviewing this post, and Johann Mabille for our interactions on the &lt;code&gt;xsimd&lt;/code&gt; project.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/02/25/enforce-code-consistency-clang-format" title="Enforce code consistency with clang-format"&gt;Enforce code consistency with clang-format&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Serge Guelton</dc:creator><dc:date>2022-02-25T07:00:00Z</dc:date></entry><entry><title type="html">This Week in JBoss - February 25th 2022</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2022-02-25.html" /><category term="" /><author><name>Jason Porter</name><uri>https://www.jboss.org/people/jason-porter</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2022-02-25.html</id><updated>2022-02-25T00:00:00Z</updated><content type="html">&lt;article class="" data-tags=""&gt; &lt;h1&gt;This Week in JBoss - February 25th 2022&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Welcome back! What better way to finish off the week (or start the week depending on when you read this) than by seeing what’s new in the software you care about? As always, we have some great things happening within the community, read on below.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_releases"&gt;Releases&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Quarkus 2.7.2.Final - second maintenance release for the 2.7 branch. This release features a number of bug fixes and updates to Kogito and Optaplanner. &lt;a href="https://github.com/quarkusio/quarkus/releases/tag/2.7.2.Final"&gt;View the full changelog&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Kogito 1.17.0 - This release packs in new features, bug fixes and, one small breaking change. &lt;a href="https://blog.kie.org/2022/02/kogito-1-17-0-released.html"&gt;Read about the release&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Eclipse Vertx 4.2.5 - The Vertx team has been hard at work bringing the number of bugs down in the 4.2 branch. They have also added the ability to intercept HttpProxy calls, and the Oracle client now has proper pooling. &lt;a href="https://vertx.io/blog/eclipse-vert-x-4-2-5/"&gt;Find out more&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Keycloak 17.0.0 - A major update, too many things to list here, &lt;a href="https://www.keycloak.org/2022/02/keycloak-1700-released"&gt;read about the release for changes&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Hibernate Reactive 1.1.3.Final - Biggest change here: Support for Oracle, &lt;a href="https://in.relation.to/2022/02/11/hibernate-reactive-1_1_3_Final/"&gt;see more&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_blogs"&gt;Blogs&lt;/h3&gt; &lt;p&gt;The blog, Mastertheboss has some great posts about Quarkus:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/soa-cloud/quarkus/how-to-configure-logging-with-quarkus/"&gt;How to configure logging with Quarkus&lt;/a&gt; - to get a primer on logging within Quarkus.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/keycloak/getting-started-with-keycloak-powered-by-quarkus/"&gt;Getting started with Keycloak powered by Quarkus&lt;/a&gt; goes along well with the recent release of Keycloak 17 since the default runtime is now Quarkus.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/soa-cloud/quarkus/getting-started-with-stork-service-discovery-on-quarkus/"&gt;Getting started with Stork Service Discovery on Quarkus&lt;/a&gt; gets you started using Stork for that all important Service Discovery bit of your MSA application.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt;The KIE team (business and process automation space) also have three new blog posts out recently:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/02/saga-pattern-with-processes-and-kogito-part-2.html"&gt;SAGA PATTERN WITH PROCESSES AND KOGITO – PART 2&lt;/a&gt; - the second part of a series using the SAGA pattern with Kogito. This one focuses on an Order fulfillment implementation.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/02/kie-tools-examples-implementing-a-ping-pong-view-in-angular.html"&gt;KIE TOOLS EXAMPLES – IMPLEMENTING A PING PONG VIEW IN ANGULAR&lt;/a&gt; expands on creating custom views using the Envelope API using Angular instead of React.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/02/json-datasets-in-dashbuilder.html"&gt;JSON DATASETS IN DASHBUILDER&lt;/a&gt; demonstrates how to use JSON datasets within DashBuilder and briefly touching on future directions for the tech.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt;Those working on Quarkus have a few new things to show and say this week as well:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-superheroes-to-the-rescue/"&gt;Quarkus Superheroes to the Rescue!&lt;/a&gt; walks through the full Quarkus Superheroes application including deployment, docker, dev mode, and the architecture.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/stork-kubernetes-discovery/"&gt;Kubernetes Service Discovery and Selection with Stork&lt;/a&gt; covers the same ground as the Mastertheboss blog, but in a different way using different examples. You can’t go wrong with either of them.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt;Lastly, a few blogs from other areas around the blogosphere:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.keycloak.org/2022/02/dbs"&gt;Supported databases for the new Keycloak store&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.schabell.org/2022/02/devopsdays-raleigh-2022-architecture-and-career.html"&gt;DevOpsDays Raleigh 2022 - Talking Architecture and Career&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.redhat.com/sysadmin/podman-features-1"&gt;5 Podman features to try now&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt;Thanks again for joining us for another week!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/jason-porter.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Jason Porter&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Jason Porter</dc:creator></entry><entry><title type="html">SAGA PATTERN WITH PROCESSES AND KOGITO – PART 2</title><link rel="alternate" href="https://blog.kie.org/2022/02/saga-pattern-with-processes-and-kogito-part-2.html" /><author><name>Tiago Dolphine</name></author><id>https://blog.kie.org/2022/02/saga-pattern-with-processes-and-kogito-part-2.html</id><updated>2022-02-24T17:25:02Z</updated><content type="html">ORDER FULFILMENT PROCESS EXAMPLE In it was described Saga pattern and how could be used as the orchestrator, also known as Saga Coordinator Executor (SEC).  This post will cover an example of the Order Fulfilment implementation on the top of Kogito processes using , which is placed in the , to orchestrate all the steps and compensations to be executed in case of errors during the execution. The most important part of both examples is the usage of the compensation flow feature from Kogito process engine, which controls all steps that were executed and might be compensated, in a stateful manner, this means the Saga workflow can be long-lived, based on continuation, containing wait states on each step, but for simplicity, this example shows the Saga as a request-response aka straight-through process, described in more details in . In a Saga process, the compensations can be represented by using boundary Intermediate Catching Compensation Events attached to the respective step to be compensated, for instance, Cancel Payment should be attached to the Process Payment. All steps and compensations for stock, payment, and shipping should be executed to confirm or cancel an order and are defined using Service Tasks, represented by Java classes present in the project using CDI for dependency injection in Kogito runtime, more details on . Let’s cover two different approaches to design the Saga workflow for the order fulfillment example: ERROR HANDLING WITH ERROR EVENTS In this approach, it was used error events, that are thrown from the service tasks execution as Java Exceptions, where each service task represents a step of the Saga execution. All errors are caught using an event subprocess containing an error start event to handle the error until the end of the subprocess execution where the compensation flow is triggered, with the usage of an end compensation event. DATA-DRIVEN FLOW WITH GATEWAYS Within this approach, all paths in the workflow either success or error were chosen using the content of the response from each service task execution with the usage of exclusive gateways, in this scenario no error events or exceptions were used.  Given an error in response data, the compensation flow is triggered using an end compensation event. An inclusive gateway was used just for convenience to centralize the call to the order service, indicating the order has failed. EXAMPLES USAGE The interaction with the application was based on REST APIs, generated out-of-the-box by Kogito to interact with the process which is orchestrating the Saga. The start point is to submit a request responsible to create a new order with a given orderId, this could be any other payload that represents an order resource, external to the process, but for the sake of simplicity, in this example, it will be based on an id that could be seen as a correlation to client starting the Saga. The output of each step is represented by a Response object that contains a type, indicating success or error and the id of the resource that was invoked in the service, for instance, for payment, it represents the payment id, but this could be any kind of response depending on the implementation of each service. In the case of the Error handling example, instead of a response indicating an error, a Java exception is thrown from the service. Running and testing the example: mvn clean package java -jar target/quarkus-app/quarkus-run.jar Creating a new Sucess Order POST /order OR /order_saga_error { "orderId" : "03e6cf79-3301-434b-b5e1-d6899b5639aa" } The response for the main request is returned with attributes representing the response of each step execution, either success or failure. The orderResponse attribute indicates if the order can be confirmed by the client starting the Saga process, in case of success or canceled, in case of error. { "id": "df3c9c1e-8af4-4458-9a48-e2ab6f8944ed", "stockResponse": { "type": "SUCCESS", "resourceId": "b66149ab-118c-42f2-ae0d-01501425e597" }, "paymentResponse": { "type": "SUCCESS", "resourceId": "857d90e6-a607-4d42-ba41-594b92ed5ee6" }, "orderId": "03e6cf79-3301-434b-b5e1-d6899b5639aa", "orderResponse": { "type": "SUCCESS", "resourceId": "03e6cf79-3301-434b-b5e1-d6899b5639aa" }, "shippingResponse": { "type": "SUCCESS", "resourceId": "6b2af61d-e016-4ac4-a30a-ce0d2c0b332e" } } In the console executing the application, you can check the log with information on the executed steps, that come from java service classes. 2022-02-24 14:09:48,415 INFO [org.kie.kog.StockService] (executor-thread-0) Reserve Stock for order 03e6cf79-3301-434b-b5e1-d6899b5639aa 2022-02-24 14:09:48,417 INFO [org.kie.kog.PaymentService] (executor-thread-0) Process Payment for order 03e6cf79-3301-434b-b5e1-d6899b5639aa 2022-02-24 14:09:48,418 INFO [org.kie.kog.ShippingService] (executor-thread-0) Schedule Shipping for order 03e6cf79-3301-434b-b5e1-d6899b5639aa 2022-02-24 14:09:48,420 INFO [org.kie.kog.OrderService] (executor-thread-0) Order Success for order 03e6cf79-3301-434b-b5e1-d6899b5639aa Simulating errors to activate the compensation flows To make testing the process easier it was introduced an optional attribute failService that indicates which service should respond with an error. The attribute is basically the simple class name of the service. POST /order OR /order_saga_error { "orderId": "03e6cf79-3301-434b-b5e1-d6899b5639aa", "failService" : "ShippingService" } Response example: { "id": "9333f775-3b19-4fe4-abb0-cdd23911b239", "stockResponse": { "type": "SUCCESS", "resourceId": "305f4ab6-4072-4786-a2a9-7ec8a52c4bed" }, "paymentResponse": { "type": "SUCCESS", "resourceId": "f98b16a9-ff44-4c81-be27-df732a8c5473" }, "orderId": "03e6cf79-3301-434b-b5e1-d6899b5639aa", "orderResponse": { "type": "ERROR", "resourceId": "03e6cf79-3301-434b-b5e1-d6899b5639aa" }, "shippingResponse": { "type": "ERROR", "resourceId": "4cc49235-7236-45cf-8cd8-87b5cb916f1d" } } In the console executing the application, you can check the log with the executed steps. 2022-02-24 14:07:40,980 INFO [org.kie.kog.StockService] (executor-thread-0) Reserve Stock for order 03e6cf79-3301-434b-b5e1-d6899b5639aa 2022-02-24 14:07:40,982 INFO [org.kie.kog.PaymentService] (executor-thread-0) Process Payment for order 03e6cf79-3301-434b-b5e1-d6899b5639aa 2022-02-24 14:07:40,983 INFO [org.kie.kog.ShippingService] (executor-thread-0) Schedule Shipping for order 03e6cf79-3301-434b-b5e1-d6899b5639aa 2022-02-24 14:07:40,985 INFO [org.kie.kog.OrderService] (executor-thread-0) Order Failed for order 03e6cf79-3301-434b-b5e1-d6899b5639aa 2022-02-24 14:07:40,986 INFO [org.kie.kog.ShippingService] (executor-thread-0) Cancel Shipping for order 4cc49235-7236-45cf-8cd8-87b5cb916f1d 2022-02-24 14:07:40,988 INFO [org.kie.kog.PaymentService] (executor-thread-0) Cancel Payment for payment f98b16a9-ff44-4c81-be27-df732a8c5473 2022-02-24 14:07:40,989 INFO [org.kie.kog.StockService] (executor-thread-0) Cancel Stock for order 305f4ab6-4072-4786-a2a9-7ec8a52c4bed It is important to mention that there are more ways to design a Saga using processes, in this post, it was covered two options to achieve a similar functionality given the use case of this example. TO BE CONTINUED… The 3rd blog post will demonstrate how to implement the same order fulfillment Saga using on the top of kogito for the orchestrator, stay tuned. The post appeared first on .</content><dc:creator>Tiago Dolphine</dc:creator></entry><entry><title>SQL cache stores and more in Data Grid 8.3</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/02/24/sql-cache-stores-and-more-data-grid-83" /><author><name>Shaaf, Syed</name></author><id>914e37ea-a0bc-4312-a1bb-36107f69cf47</id><updated>2022-02-24T07:00:00Z</updated><published>2022-02-24T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/products/datagrid/overview"&gt;Red Hat Data Grid&lt;/a&gt; is a distributed, cloud-based datastore offering very fast response times as an in-memory database. The latest version, Data Grid 8.3, features cross-site replication with more observability and two new types of SQL cache store for scaling applications with large datasets. This version also brings improved security, support for Helm charts, and a better command-line interface (CLI).&lt;/p&gt; &lt;p&gt;This article is an overview of new features and enhancements in this latest version of Red Hat Data Grid.&lt;/p&gt; &lt;h2&gt;Cross-site replication with more observability&lt;/h2&gt; &lt;p&gt;With the latest Data Grid release, you can track cross-site replication operations for each of the backup locations and their caches, including response times and the number of RELAY messages exchanged, as shown in Figure 1.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/repl.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/repl.png?itok=XUT5njPx" width="1440" height="584" alt="Cross-site replication involves messages at many different levels." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. Cross-site replication involves messages at many different levels. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;We have also enabled access to the data via the CLI, the REST API, and Java Management Extensions (JMX) to offer a better user experience to cluster operators. Cross-site replication is also more transparent and observable due to dedicated, operator-managed pods for routing cross-site replication requests.&lt;/p&gt; &lt;p&gt;Data Grid operators can also configure the number of relay nodes for cross-site replication. This flexibility enhances the cache's scalability and performance over multiple sites.&lt;/p&gt; &lt;p&gt;Finally, security is of paramount importance for a cross-site cluster, so we have enabled TLS security for router-based cross-site replication. (Scroll down for more about security enhancements in a later section.)&lt;/p&gt; &lt;h2&gt;Scaling with SQL cache stores&lt;/h2&gt; &lt;p&gt;What do you do if you have a lot of data in a database and want to load the data into the cache? Database schemas can be complex and users might want to define how that data is queried through operations such as SELECT, INSERT, and so on. Perhaps you would also like to support write-through and write-back operations. All of this makes for a complex scenario.&lt;/p&gt; &lt;p&gt;In this release, we have added two types of SQL cache store:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Table cache store: Loads all data from a single table. Only the table name is required.&lt;/li&gt; &lt;li&gt;Query cache store: Loads data based on SQL queries.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Useful things you can do with the new SQL cache stores include the following:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Pre-load data from an existing database.&lt;/li&gt; &lt;li&gt;Expose cache data with a user-defined schema.&lt;/li&gt; &lt;li&gt;Allow read and write operations.&lt;/li&gt; &lt;li&gt;Configure the cache store as read-only, and act as a cache loader.&lt;/li&gt; &lt;li&gt;Configure the cache store to load values on startup.&lt;/li&gt; &lt;li&gt;Use the cache store with composite keys and values through the &lt;a href="https://developers.google.com/protocol-buffers"&gt;protocol buffers (protobuf) schema&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;With the query cache store, use arbitrary select, select all, delete, delete all, and upsert operations.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;To set up a cache store, you simply need to drop the database drivers into the server, which can be done with the &lt;a href=""&gt;Operator&lt;/a&gt; custom resource (CR) on &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;. After that, users should be able to create SQL cache stores via YAML, JSON, or XML—also a new configuration feature. An &lt;a href="https://github.com/redhat-mw-demos/infinispan-sqlstore-demo"&gt;example using Infinispan and the Quarkus Java framework&lt;/a&gt; is available on GitHub.&lt;/p&gt; &lt;h2&gt;More security enhancements&lt;/h2&gt; &lt;p&gt;Data Grid now provides full support for TLS version 1.3 with OpenSSL native acceleration. We have also increased the flexibility and convenience of security in Data Grid 8.3.&lt;/p&gt; &lt;h3&gt;Multiple realms&lt;/h3&gt; &lt;p&gt;You can combine multiple security realms into a single realm. When authenticating users, Data Grid Server checks each security realm in turn until it finds one that can perform the authentication.&lt;/p&gt; &lt;p&gt;The following example security realm includes an LDAP realm and a property realm, along with the &lt;code&gt;distributed-realm&lt;/code&gt; element:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt;&lt;security-realms&gt; &lt;security-realm name="my-distributed-realm"&gt; &lt;ldap-realm&gt; &lt;!-- LDAP realm configuration. --&gt; &lt;/ldap-realm&gt; &lt;properties-realm&gt; &lt;!-- Property realm configuration. --&gt; &lt;/properties-realm&gt; &lt;distributed-realm/&gt; &lt;/security-realm&gt; &lt;/security-realms&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Multiple endpoints&lt;/h3&gt; &lt;p&gt;Users can now also configure multiple endpoints and define separate security realms for them. This enhancement enables more flexible and secure use.&lt;/p&gt; &lt;p&gt;The following example contains two different endpoint configurations. One endpoint binds to a &lt;code&gt;public&lt;/code&gt; socket, uses an &lt;code&gt;application&lt;/code&gt; security realm, and disables administrative features. Another endpoint binds to a &lt;code&gt;private&lt;/code&gt; socket, uses a &lt;code&gt;management&lt;/code&gt; security realm, and enables administrative features:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt;&lt;endpoints&gt; &lt;endpoint socket-binding="public" security-realm="application" admin="false"&gt; &lt;hotrod-connector/&gt; &lt;rest-connector/&gt; &lt;/endpoint&gt; &lt;endpoint socket-binding="private" security-realm="management"&gt; &lt;hotrod-connector/&gt; &lt;rest-connector/&gt; &lt;/endpoint&gt; &lt;/endpoints&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;PEM files&lt;/h3&gt; &lt;p&gt;Users can now add PEM files directly to their Data Grid Server configuration and use them as trust stores and keystores in a TLS server identity.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; See the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.3/html-single/data_grid_security_guide/"&gt;Data Grid Security Guide&lt;/a&gt; and &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.3/html-single/data_grid_server_guide#distributed-security-realms_security-realms"&gt;Distributed security realms&lt;/a&gt; to learn more about new security features in Data Grid 8.3.&lt;/p&gt; &lt;h2&gt;Deploy Data Grid with Helm charts&lt;/h2&gt; &lt;p&gt;Developers who use &lt;a href="https://helm.sh"&gt;Helm charts&lt;/a&gt; for application deployment can now use this convenient mechanism to install Data Grid. You can use charts to deploy Data Grid instances, configure clusters, add authentication and authorization, add network access via routes and node ports, enable load balancers, and more, using the Data Grid portal (Figure 2) or the CLI.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/helm_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/helm_0.png?itok=1XGArnkV" width="528" height="214" alt="Helm charts can be invoked through the Data Grid graphical interface." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2. Helm charts can be invoked through the Data Grid graphical interface. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p class="Indent1"&gt; &lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; Using Helm charts is intended for sites where the Data Grid Operator is not available and operators must configure, deploy, and manage the cluster manually.&lt;/p&gt; &lt;h2&gt;CLI improvements&lt;/h2&gt; &lt;p&gt;Data Grid 8.3 has a few updates for developers who prefer working on the command line. For one, you can enable and disable rebalancing of the cluster, track and extract more details about cross-site replication relay nodes, and manage cache availability. Additionally, if you use the general &lt;code&gt;oc&lt;/code&gt; OpenShift command, you can now also &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.3/guide/d510c8ad-e097-4a3e-af55-e1d7967ecac3"&gt;install&lt;/a&gt; the Infinispan extension and use it with &lt;code&gt;oc&lt;/code&gt;, as shown in Figure 3.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/control.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/control.png?itok=heoMJq24" width="427" height="258" alt="You can control a Data Grid cluster from the command line." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3. You can control a Data Grid cluster from the command line. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Usability improvements&lt;/h2&gt; &lt;p&gt;We've made a few more improvements to increase the usability of Data Grid in this release:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Data Grid 8.3 has full support for &lt;a href="https://developers.redhat.com/articles/2021/12/14/explore-java-17-language-features-quarkus"&gt;Java 17&lt;/a&gt; for embedded and remote caches.&lt;/li&gt; &lt;li&gt;You can automatically migrate any file-store configuration during the upgrade to Data Grid 8.3.&lt;/li&gt; &lt;li&gt;You can now delete entries with the &lt;a href="https://access.redhat.com/documentation/ru-ru/red_hat_data_grid/7.1/html/developer_guide/building_ickle_query"&gt;Ickle programming language&lt;/a&gt;: &lt;pre&gt; &lt;code&gt;query.create("DELETE FROM books WHERE page_count &gt; 500").executeStatement();&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Hot Rod migration is simpler when upgrading clusters of server nodes between versions and handles configuration changes transparently.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Get started with Data Grid 8.3&lt;/h2&gt; &lt;p&gt;Ready to dive in and try out Data Grid 8.3? These resources will get you started:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Zip distributions are available through the &lt;a href="https://access.redhat.com/jbossnetwork/restricted/listSoftware.html?product=data.grid&amp;downloadType=distributions"&gt;Certified Service Provider (CSP) program&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Container distributions and Operators are available in the &lt;a href="https://access.redhat.com/containers/#/product/JbossDataGrid"&gt;Red Hat Container Catalog&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Product documentation is available on the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.0/"&gt;Red Hat customer portal&lt;/a&gt;, including &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.0/html/data_grid_migration_guide/"&gt;a migration guide&lt;/a&gt; to help you migrate your existing Data Grid deployments to 8.0.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Visit the &lt;a href="https://developers.redhat.com/products/datagrid"&gt;Red Hat Data Grid&lt;/a&gt; product page to learn more about this technology.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/02/24/sql-cache-stores-and-more-data-grid-83" title="SQL cache stores and more in Data Grid 8.3"&gt;SQL cache stores and more in Data Grid 8.3&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Shaaf, Syed</dc:creator><dc:date>2022-02-24T07:00:00Z</dc:date></entry><entry><title type="html">Supported databases for the new Keycloak store</title><link rel="alternate" href="https://www.keycloak.org/2022/02/dbs" /><author><name>Stian Thorgersen</name></author><id>https://www.keycloak.org/2022/02/dbs</id><updated>2022-02-24T00:00:00Z</updated><content type="html">Maintaining a broad selection of relational database support is expensive, and also more importantly limits how well the databases can be supported. With that in mind we are looking at supporting databases at different levels; first class, second class, and community. Please fill in as we’d like to gather as much feedback as we can. FIRST CLASS DATABASES The aim of first class databases is to offer better levels of tuning and testing, better defaults, and better documentation. We will also be considering testing with different versions and variants of the selected first class databases, such as cloud services. First class databases will be the solutions we are looking towards when scaling and tuning database to accommodate large scale deployments with high-availability, including multi-region deployments. As first class databases we aim to support one traditional relational database, and a cloud native database. With this in mind we have selected PostgreSQL and CockroachDB as the best candidates. PostgreSQL is a high quality fully open source database, with many supported offerings such as: * Azure Database for PostgreSQL * Amazon RDS for PostgreSQL * BigAnimal * Cloud SQL for PostgreSQL * Cruncy Bridge * Cruncy PostgreSQL for Kubernetes * EnterpriseDB CockroachDB is an cloud native open source database, with PostgreSQL compatibility. By cloud native it means that it can scale horizontally, including spanning multiple-regions. There are some competitive solutions, but not as mature, and with less streamlined PostgreSQL compatibility. There are obviously also NoSQL and other non-relational database that could in theory be a good fit for Keycloak, but would be a lot of additional effort to support. It is also worth mentioning that we are still looking towards Infinispan as our cache layer, but are also aiming to support running Keycloak without Infinspan for smaller deployments with PostgreSQL and larger deployments with CockroachDB. SECOND CLASS DATABASES The aim for second class databases are to offer mostly the same support as we offer for any database in Keycloak today. We will only test one version, there will be no database vendor specific documentation, or any additional tuning on our end. We do hope that the majority of the Keycloak community are able to migrate to first class databases, and that this will in the end be a better solution for everyone. As such we are not currently planning on offering any second class databases long term, and rather phase out support for MySQL, MariaDB, SQL Server, and Oracle over time. COMMUNITY SUPPORTED DATABASES If there is interest from the community to support additional databases, including non-relational database, we would like to discuss and figure out how this could look like. Including making it easy to install community maintained databases, as well as continuously testing of the integration.</content><dc:creator>Stian Thorgersen</dc:creator></entry><entry><title type="html">Quarkus Newsletter #17 - February</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-newsletter-17/" /><author><name>James Cobb</name></author><id>https://quarkus.io/blog/quarkus-newsletter-17/</id><updated>2022-02-23T00:00:00Z</updated><content type="html">The February Newsletter has been published! This month, you can find an introduction to the new Quarkus Superheroes sample application as well as articles teaching you how to get started with Stork Service Discovery, Java Asynchronous Programming with Java, Distributed tracing with Istio, Quarkus and Jaeger, Monitoring Quarkus Prometheus and...</content><dc:creator>James Cobb</dc:creator></entry><entry><title type="html">KIE Tools Examples &amp;#8211; Implementing a Ping Pong View in Angular</title><link rel="alternate" href="https://blog.kie.org/2022/02/kie-tools-examples-implementing-a-ping-pong-view-in-angular.html" /><author><name>Thiago Lugli</name></author><id>https://blog.kie.org/2022/02/kie-tools-examples-implementing-a-ping-pong-view-in-angular.html</id><updated>2022-02-22T16:36:29Z</updated><content type="html">Following the on how to create custom views using our , we now expand these examples with a new view implementation, this time using Angular instead of React! In this post I’ll show how we refactored the Ping Pong View to be more generic and agnostic concerning the frontend framework used, then we’ll build an Angular implementation of the View, which can be rendered inside an IFRAME or a DIV (using !). Everything shown in this post was implemented in this PR to add new examples to our project and show that the Multiplying Architecture can be used with any framework. Photo by on REFACTORING THE PING PONG VIEW PACKAGE The first thing we had to do to make the Ping Pong View package agnostic to frontend frameworks was to, instead of taking full control of where and when to render an implementation, allow the implementation to render itself and initialize the API whenever it’s ready. In the following sections, we will see how each submodule of the Ping Pong View package was changed to support this architecture. APIS Few changes have been made to the APIs (Channel, Envelope, and external PingPongApi). The most noticeable one was the addition of new external and envelope methods to showcase how a Channel can control and obtain data from envelope implementations. This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. /** * The API of a PingPongViewApi. * * These methods are what the "external world" knows about this component. */ export interface PingPongApi { clearLogs(): void; getLastPingTimestamp(): Promise&lt;number&gt;; } hosted with ❤ by This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. /** * Methods provided by the Envelope that can be consumed by the Channel. */ export interface PingPongEnvelopeApi { pingPongView__init(association: Association, initArgs: PingPongInitArgs): Promise&lt;void&gt;; pingPongView__clearLogs(): Promise&lt;void&gt;; pingPongView__getLastPingTimestamp(): Promise&lt;number&gt;; } hosted with ❤ by ENVELOPE To start, no more “PingPongEnvelopeView.tsx” was needed since implementations would handle their rendering inside the provided container, so it was removed. This was an important and necessary step because Angular doesn’t have something similar to ReactDOM.render() that can render a React component wherever it’s called (but that can be solved with Web Components, as we will see shortly). The PingPongEnvelopeApiImpl also received some changes. The pingPongView__init() method doesn’t need to wait for the view implementation to render before calling its factory create() method anymore, since at the time it’s called the view is rendered and ready. This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. export class PingPongEnvelopeApiImpl implements PingPongEnvelopeApi { constructor( private readonly args: EnvelopeApiFactoryArgs&lt;PingPongEnvelopeApi, PingPongChannelApi, void, {}&gt;, private readonly pingPongViewFactory: PingPongFactory ) {} pingPongApi?: () =&gt; PingPongApi | null; public async pingPongView__init(association: Association, initArgs: PingPongInitArgs) { this.args.envelopeClient.associate(association.origin, association.envelopeServerId); this.pingPongApi = this.pingPongViewFactory.create(initArgs, this.args.envelopeClient.manager.clientApi); } public async pingPongView__clearLogs() { this.pingPongApi?.()?.clearLogs(); } public async pingPongView__getLastPingTimestamp() { const api = this.pingPongApi?.(); if (!api) return Promise.resolve(0); return api.getLastPingTimestamp(); } } hosted with ❤ by EMBEDDED Here are convenient React components to be used for integrating any Ping Pong View implementations. These components forward their refs, which, in this case, are the implementations of the PingPongApi, returned by the create() method from the PingPongFactory of your custom view. In the case of iFrames, the implementation should provide an entry point URL (the “envelopePath”). For DIVs, it should provide a “renderView” method that receives the container where it should be displayed and the envelope ID to be mapped. Once the view is rendered the envelope can be initialized via PingPongViewEnvelope.init(). One of the parameters passed should be an instance of the PingPongFactory from your implementation. This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. export class PingPongApiService implements PingPongFactory { … create(initArgs: PingPongInitArgs, channelApi: MessageBusClientApi&lt;PingPongChannelApi&gt;) { … return () =&gt; { … } as PingPongApi; } pingPongApiService = new PingPongApiService(); // Initialize envelope with the container config, the bus, // and factory (in this case, a service that implements the "create" method). // This should be called after the view is rendered, // inside a `ngOnInit` or `useEffect` for example. PingPongViewEnvelope.init({ config: { containerType: this.containerType, envelopeId: this.envelopeId! }, bus: { postMessage: (message, _targetOrigin, transfer) =&gt; window.parent.postMessage(message, "*", transfer) }, pingPongViewFactory: this.pingPongApiService, }); hosted with ❤ by IMPLEMENTING PING PONG VIEW IN ANGULAR Any Angular application, after being built, results in an index.html file that loads multiple .js files (polyfills.js, runtime.js, and main.js). This is fine when we are running the application by itself or inside an iFrame, but if we want to render it in a DIV (or any other HTML Element) Angular doesn’t provide a utility such as ReactDOM.render(). What it does provide is a simple way to create a Web Component that can be used anywhere! So in this section, we will see how to implement a Ping Pong View in Angular and then build a Web Component from an Angular application. THE APPLICATION If you are new to Angular, the from the Angular documentation is great! But don’t worry, we will start from the beginning, creating an Angular application from the ground up. First, make sure that you have angular/cli installed globally: npm install -g @angular/cli Now create a new Angular project with the following command: ng new ping-pong-view-angular (using Angular routing and any stylesheet formatting other than CSS is optional) You should get a template project like this! We can now go ahead and create our Ping Pong module with a component and service: cd src/app ng generate module ping-pong cd ping-pong ng generate component ping-pong --flat ng generate service ping-pong-api Great! Now, before implementing the component and service, let’s make sure that the ping-pong component is rendered correctly in our app component (which is the application entry point). For that, edit the app.component.html file, removing everything and adding the ping-pong component: &lt;app-ping-pong&gt;&lt;/app-ping-pong&gt; PING PONG API SERVICE In Angular, services can have many uses, the most common ones being to interface with external APIs and keep a state of values used across the application. For this project, we want to use the Channel API provided by the Envelope while keeping a local state of all pings and pongs sent and received. A great way to do this is to make the PingPongApiService class also implement the PingPongFactory interface, passing an instance of it to the PingPongViewEnvelope init() method (to later have our PingPongApiService create() being called inside PingPongEnvelopeApiImpl.pingPongView__init() passing the necessary initial arguments and the Client API). This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. import { Injectable } from "@angular/core"; import { MessageBusClientApi } from "@kie-tools-core/envelope-bus/dist/api"; import { PingPongChannelApi, PingPongInitArgs } from "@kie-tools-examples/ping-pong-view/dist/api"; import { PingPongFactory } from "@kie-tools-examples/ping-pong-view/dist/envelope"; import { ReplaySubject, BehaviorSubject, Subject } from "rxjs"; declare global { interface Window { initArgs: PingPongInitArgs; channelApi: PingPongChannelApi; } } export interface LogEntry { line: string; time: number; } function getCurrentTime() { return Date.now(); } @Injectable({ providedIn: 'root', }) export class PingPongApiService implements PingPongFactory { channelApi: MessageBusClientApi&lt;PingPongChannelApi&gt;; initArgs: PingPongInitArgs; log = new ReplaySubject&lt;LogEntry&gt;(10); logCleared = new Subject(); lastPingTimestamp = new BehaviorSubject&lt;number&gt;(0); dotInterval?: number; initialized = false; pingSubscription?: (source: string) =&gt; void; pongSubscription?: (source: string, replyingTo: string) =&gt; void; constructor() {} create(initArgs: PingPongInitArgs, channelApi: MessageBusClientApi&lt;PingPongChannelApi&gt;) { // Making sure we don't subscribe more than once. this.clearSubscriptions(); this.clearInterval(); this.initArgs = initArgs; this.channelApi = channelApi; // Subscribe to ping notifications. this.pingSubscription = this.channelApi.notifications.pingPongView__ping.subscribe((pingSource) =&gt; { // If this instance sent the PING, we ignore it. if (pingSource === this.initArgs.name) { return; } // Add a new line to our log, stating that we received a ping. this.log.next({ line: `PING from '${pingSource}'.`, time: getCurrentTime() }); // Acknowledges the PING message by sending back a PONG message. this.channelApi.notifications.pingPongView__pong.send(this.initArgs.name, pingSource); }); // Subscribe to pong notifications. this.pongSubscription = this.channelApi.notifications.pingPongView__pong.subscribe( (pongSource: string, replyingTo: string) =&gt; { // If this instance sent the PONG, or if this PONG was not meant to this instance, we ignore it. if (pongSource === this.initArgs.name || replyingTo !== this.initArgs.name) { return; } // Updates the log to show a feedback that a PONG message was observed. this.log.next({ line: `PONG from '${pongSource}'.`, time: getCurrentTime() }); } ); // Populate the log with a dot each 2 seconds. this.dotInterval = window.setInterval(() =&gt; { this.log.next({ line: ".", time: getCurrentTime() }); }, 2000); this.initialized = true; return () =&gt; ({ clearLogs: () =&gt; { this.log = new ReplaySubject&lt;LogEntry&gt;(10); // Emit a value to logCleared so we can re-subscribe to this.log wherever needed. this.logCleared.next(null); }, getLastPingTimestamp: () =&gt; { return Promise.resolve(this.lastPingTimestamp.value); }, }); } // Send a ping to the channel. ping() { this.channelApi.notifications.pingPongView__ping.send(this.initArgs.name); this.lastPingTimestamp.next(getCurrentTime()); } clearSubscriptions() { this.pingSubscription &amp;amp;&amp; this.channelApi.notifications.pingPongView__ping.unsubscribe(this.pingSubscription); this.pongSubscription &amp;amp;&amp; this.channelApi.notifications.pingPongView__pong.unsubscribe(this.pongSubscription); } clearInterval() { window.clearInterval(this.dotInterval); } ngOnDestroy() { this.clearSubscriptions(); this.clearInterval(); } } hosted with ❤ by PING PONG COMPONENT Our component should both initialize and consume the Ping Pong Api Service, and then, display the pings and pongs logs. This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. import { PingPongApiService, LogEntry } from "./ping-pong-api.service"; import { Component, Input, OnInit } from "@angular/core"; import * as PingPongViewEnvelope from "@kie-tools-examples/ping-pong-view/dist/envelope"; import { ContainerType } from "@kie-tools-core/envelope/dist/api"; import { Observable, scan } from "rxjs"; @Component({ selector: "app-ping-pong", templateUrl: "./ping-pong.component.html", styleUrls: ["./ping-pong.component.css"], providers: [], }) export class PingPongComponent implements OnInit { @Input() containerType: ContainerType = ContainerType.IFRAME; @Input() envelopeId?: string; constructor(public pingPongApiService: PingPongApiService) {} log: Observable&lt;LogEntry[]&gt;; subscribeToLogUpdates() { this.log = this.pingPongApiService.log.asObservable().pipe(scan((acc, curr) =&gt; […acc.slice(–9), curr], [])); } ngOnInit() { // Initialize log with a starting message. this.pingPongApiService.log.next({ line: "Logs will show up here", time: 0 }); // Initialize envelope with the container config, the bus, // and factory (in this case, a service that implements the "create" method). PingPongViewEnvelope.init({ config: { containerType: this.containerType, envelopeId: this.envelopeId! }, bus: { postMessage: (message, _targetOrigin, transfer) =&gt; window.parent.postMessage(message, "*", transfer) }, pingPongViewFactory: this.pingPongApiService, }); // Create an observable variable with the 10 latest values of the log. this.subscribeToLogUpdates(); this.pingPongApiService.logCleared.subscribe(() =&gt; this.subscribeToLogUpdates()); } } hosted with ❤ by Notice that the component has two Input() arguments, these arguments are the equivalent of props in a React component, and they serve to receive values from a parent component. They are needed here to differentiate when the ping-pong component is being rendered in a DIV or an iFrame. By default, it’ll assume it’s in an iFrame so these inputs don’t need to be set, but later on, we will see how to set them so that the component works as a Web Component. On init (via ngOnInit) the PingPongViewEnvelope is initialized, receiving the instance of our Ping Pong Api Service as a Ping Pong Factory, and at this point, the Channel and Envelope will start to communicate with each other. So far, so good! But we still need to display the ping pong logs somewhere! That’s where the ping-pong.component.html template file comes in. As long as it is mapped as the template file for the component, everything publicly available in the PingPongComponent class can be used in the template, like so: This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. &lt;div class="ping-pong-view–main"&gt; &lt;h2&gt;This is an implementation of Ping-Pong View in Angular&lt;/h2&gt; &lt;p class="ping-pong-view–p-iframe"&gt; The envelope boundary border is green. It can be an iFrame or a Div. (It's possible to use Div if using web components made from Angular components) &lt;/p&gt; &lt;p class="ping-pong-view–p-ping-pong"&gt;The Ping-Pong View implementation border is red&lt;/p&gt; &lt;div class="ping-pong-view–container"&gt; &lt;i&gt;#{{ pingPongApiService.initArgs?.name }}&lt;/i&gt; &lt;div class="ping-pong-view–header"&gt; &lt;span&gt;Hello from Angular!&lt;/span&gt; &lt;button (click)="pingPongApiService.ping()"&gt;Ping others!&lt;/button&gt; &lt;/div&gt; &lt;div class="ping-pong-view–log"&gt; &lt;p *ngFor="let entry of log | async" class="ping-pong-view–line"&gt; {{ entry.line }} &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; hosted with ❤ by PING PONG MODULE Lastly, we can edit our ping-pong.module.ts file with everything we’ve just created: This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. import { PingPongApiService } from "./ping-pong-api.service"; import { NgModule } from "@angular/core"; import { BrowserModule } from "@angular/platform-browser"; import { PingPongComponent } from "./ping-pong.component"; @NgModule({ declarations: [PingPongComponent], imports: [BrowserModule], exports: [PingPongComponent], providers: [PingPongApiService], bootstrap: [PingPongComponent], }) export class PingPongModule {} hosted with ❤ by And that’s it! We now have an Angular application running a Ping Pong View implementation! But how can it run in a DIV? BUILDING A WEB COMPONENT FROM AN ANGULAR APP When Angular 6 was released, along with it, was released a new utility package: angular/elements. It provides everything needed to build Web Components from Angular applications. You can read more about it ! This new tool now comes in handy for us, since our application so far is just a simple component and service. In the next steps, we will learn how to create a Web Component from an Angular module. WEB COMPONENT MODULE First, let’s create a new module with the following command at the root of our project: ng generate module web-component Then create a component in the web-component directory: cd src/app/web-component ng generate component web-component --flat WRAPPER COMPONENT The web-component.component.ts file should only be a wrapper for the Ping Pong component, passing the containerType and envelopeId inputs. This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. import { Component, Input } from "@angular/core"; import { ContainerType } from "@kie-tools-core/envelope/dist/api"; @Component({ selector: "ping-pong-wc", template: `&lt;app-ping-pong [containerType]="containerType" [envelopeId]="envelopeId"&gt;&lt;/app-ping-pong&gt;`, }) export class PingPongWcComponent { @Input("containertype") containerType: ContainerType; @Input("envelopeid") envelopeId: string; } hosted with ❤ by MODULE In the web-component.module.ts file is where the magic happens! That’s where we will take advantage of angular/elements to create a custom element (a.k.a Web Component). It should look something like this: This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. import { NgModule, Injector, DoBootstrap } from "@angular/core"; import { BrowserModule } from "@angular/platform-browser"; import { createCustomElement } from "@angular/elements"; import { PingPongModule } from "../ping-pong/ping-pong.module"; import { PingPongWcComponent } from "./web-component.component"; @NgModule({ declarations: [PingPongWcComponent], imports: [BrowserModule, PingPongModule], entryComponents: [PingPongWcComponent], providers: [], }) export class WebComponentModule implements DoBootstrap { constructor(private injector: Injector) {} ngDoBootstrap() { const element = createCustomElement(PingPongWcComponent, { injector: this.injector }); customElements.define("ping-pong-angular", element); } } hosted with ❤ by THE WEB-COMPONENT BUILD Angular allows us to have multiple builds in the same project, this makes it possible to build multiple applications, packages, and libraries from a singular Angular project. This is great news for us because we want to build an Angular application to render in an iFrame, but we also want to build a Web Component, using the same components and services! Whenever we bootstrap a new Angular project a main.ts file is automatically generated, this is the application entry point, basically where the main module should be loaded to a web page (the App module by default). For our web component, we need a new and different main file, so that it can be the entry point for the component.  In the same folder of the web component module, create a file named web-component.main.ts with the following content: This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. import { WebComponentModule } from "./web-component.module"; import { platformBrowserDynamic } from "@angular/platform-browser-dynamic"; const bootstrap = () =&gt; platformBrowserDynamic().bootstrapModule(WebComponentModule); bootstrap().catch((err) =&gt; console.error(err)); hosted with ❤ by It’s almost identical to the main.ts created by Angular, but it loads the WebComponentModule instead of the AppModule. But it’s not over yet, we need to declare this new project so that angular/cli can figure out how to build it. This is where we edit the angular.json file, adding a new “project” to it, alongside the ping-pong-view-angular one. Let’s call it “ping-pong-view-wc”: This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. { "$schema": "./node_modules/@angular/cli/lib/config/schema.json", "version": 1, "newProjectRoot": "projects", "cli": { "packageManager": "yarn" }, "projects": { "ping-pong-view-angular": { … }, "ping-pong-view-wc": { "projectType": "application", "root": "", "sourceRoot": "src", "architect": { "build": { "builder": "@angular-devkit/build-angular:browser", "options": { "outputPath": "dist/wc", "index": "src/index.html", "main": "src/app/web-component/web-component.main.ts", "polyfills": "src/polyfills.ts", "tsConfig": "tsconfig.wc.json", "aot": true, "assets": ["src/favicon.ico", "src/assets"], "styles": ["src/styles.css"], "scripts": [] }, "configurations": { "production": { "fileReplacements": [ { "replace": "src/environments/environment.ts", "with": "src/environments/environment.prod.ts" } ], "optimization": true, "outputHashing": "none", "sourceMap": false, "namedChunks": false, "extractLicenses": true, "vendorChunk": false, "buildOptimizer": true, "budgets": [ { "type": "initial", "maximumWarning": "500kb", "maximumError": "1mb" }, { "type": "anyComponentStyle", "maximumWarning": "2kb", "maximumError": "4kb" } ] } } } } } }, "defaultProject": "ping-pong-view-angular" } hosted with ❤ by It’s important to create a new tsconfig file specifically for this new build so that the correct files are included and the build is output to a new directory: This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. { "extends": "./tsconfig.json", "compilerOptions": { "outDir": "./dist/wc", "types": [] }, "files": ["src/app/web-component/web-component.main.ts", "src/polyfills.ts"], "include": ["src/app/web-component/*.d.ts"] } hosted with ❤ by BUILD SCRIPTS Finally is time to build our Web Component, and for that new scripts can be added to your package.json: "scripts": { ... "build:wc": "ng build ping-pong-view-wc &amp;amp;&amp; yarn run build:wc:concat", "build:wc:concat": "cat dist/wc/polyfills.js dist/wc/runtime.js dist/wc/main.js &gt; dist/wc/index.js", ... } The “build:wc:concat” command is useful to generate a single file to be loaded wherever this web-component is used, making it simple to use, instead of loading all 3 files every time. That’s it, we’re finally done, right? Well, not quite… MULTIPLE PING-PONG-VIEW WEB COMPONENTS ON THE SAME PAGE What would happen if we loaded multiple ping-pong-view web components on the same page? In theory, everything should be fine, because all web components should be self-contained. And they are! But , and without any changes, every ping-pong web component will be using the same instance of the PingPongApiService. Thankfully, Angular provides an easy way to fix that! Remember our ping-pong-api.service.ts? It declares an Angular service that implements the PingPongFactory interface, but by default, Angular makes it an Injectable service that is provided in the “root” of our project, like this: @Injectable({ providedIn: 'root', }) export class PingPongApiService implements PingPongFactory { ... Well, to make it not behave as a singleton, we just need to remove the “providedIn” property: @Injectable() export class PingPongApiService implements PingPongFactory { ... And, so that our component can still inject the service as its dependency, we need to set it as a provider. In the ping-pong.component.ts file add PingPongApiService as a Provider like this: @Component({ selector: "app-ping-pong", templateUrl: "./ping-pong.component.html", styleUrls: ["./ping-pong.component.css"], providers: [PingPongApiService], }) export class PingPongComponent implements OnInit { ... And now we are finally done! As long as you load the built index.js file as a script wherever you want (even inside a React component) you can load the web component by its name: &lt;ping-pong-angular containerType="div" envelopeId="..."&gt;&lt;/ping-pong-angular&gt; Congrats on building your Angular application implementing a Ping Pong View! If you have any questions feel free to post in the comments section below. Also, check out the original implementation in our project, along with the one made entirely in React! The post appeared first on .</content><dc:creator>Thiago Lugli</dc:creator></entry></feed>
